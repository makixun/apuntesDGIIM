% --------------------------------------------------------------------------------
% Sucesiones y series de funciones.
% --------------------------------------------------------------------------------

\section{Sucesiones y series de funciones}

\begin{ejer}
  Probar que el espacio $\mathcal{C}_B(A,\mathbb{R}^M)$ es un espacio de Banach, esto es, un espacio normado y completo.
\end{ejer}

  \begin{sol}
    Empezamos probando que $(\mathcal{C}_B(A, \mathbb R^M), \|\cdot \|_\infty)$ es un espacio normado:
    \begin{itemize}

    \item  Positividad. En primer lugar puesto que la norma se ha definido como supremo de un conjunto de numeros positivos, tendremos que $\|f\|_\infty \geq 0$ para toda $f\in (\mathcal{C}_B(A, \mathbb R^M)$. Además, $|f\|_\infty=0 \iff sup_{x \in A}|f(x)|=0 \iff f(x)=0, \ \forall x \in A \iff f$ es la función 0.
    \item Homogeneidad. Si $k \in \mathbb R \text{ entonces } \|kf\|_\infty=|k|\|f\|_\infty \iff sup_{x \in A}|kf(x)|=sup_{x \in A}|k||f(x)|=|k|sup_{x \in A}|f(x)| = |k| \| f\|_\infty$.
    \item Desigualdad triangular.
      $\|f+g\|_\infty \leq \|f|_\infty + \|g|_\infty\iff sup_{x \in A}|f(x)+g(x)| \leq sup_{x \in A}|f(x)| + sup_{x \in A}|g(x)|$.
      Para cualesquiera $f, g \in \mathcal{C}_B(A, \mathbb R^M)$.
    \end{itemize}

    Para demostrar que ${f_n} \to f$  c.u. en A $\iff f_n \to f\ en\ \mathcal{C}_B(A, \mathbb R^M)$, solo tenemos que observar que ${f_n} \to f$  c.u. en A  significa que: $$\forall \epsilon>0 \ \ \exists n_0\in \mathbb N \ :\ n\geq n_0 \Rightarrow |f_n(x)-f(x) |<\epsilon , \ \forall x\in A,$$
    lo cual equivale a decir $$\forall \epsilon>0 \ \ \exists n_0\in \mathbb N \ :\ n\geq n_0 \Rightarrow \|f_n-f\|_\infty = sup_{x \in A} |f_n-f| \leq \epsilon , \ \forall x\in A,$$
    es decir, $f_n \to f\ en\ \mathcal{C}_B(A, \mathbb R^M)$.

    Por último, $\mathcal{C}_B(A, \mathbb R^M)$ es de Banach si es completo, es decir si toda sucesión $\{ f_n\}$ (de funciones en $\mathcal{C}_B(A, \mathbb R^M)$) de Cauchy converge. La prueba es análoga a la que se hizo para ver que $\mathcal{C}(A,\mathbb{R}^M)$, con $A \subseteq \mathbb{R}^N$ compacto, era completo. La única diferencia será que tras probar la convergencia uniforme de $f_n$ a una función  $f$, deberemos probar que $f\in \mathcal{C}_B(A,\mathbb{R}^M)$, es decir que el límite uniforme de la sucesión $\{f_n\}$ de funciones continuas y acotadas es una función continua y acotada. Veámoslo.

    Recordemos que ya sabemos por teoría que $f$ es continua. Para la acotación, tomando $\epsilon = 1$ en la definición de convergencia uniforme, obtenemos un $n_0 \in \mathbb{N}$ tal que $n \ge n_0 \Rightarrow |f_n(x) - f(x)| < 1\ \forall x \in A$. Por otro lado, como $f_{n_0}$ es acotada, existe un $M>0$ tal que $|f_{n_0}(x)| \le M\ \forall x \in A$. Entonces, se tiene que: $$|f(x)| = |f(x) - f_{n_0}(x) + f_{n_0}(x)| \le |f(x) - f_{n_0}(x)| + |f_{n_0}(x)| < 1 + M, \ \ \forall x \in A$$
    Por tanto, $f$ está acotada.
  \end{sol}

\begin{ejer}
  \label{1}
  Sea $A\subseteq \R^N$ compacto, y funciones $f_k : A \to \mathbb{R}$ continuas, verificando:

  \begin{nlist}
  \item $f_k \geq 0$
  \item $f_k(x) \geq f_{k+1}(x)\ \ \forall x \in A$ (la sucesión $\{f_k\}$ es monótona decreciente).
  \item $f_k(x) \to 0\ c.p.\ \ \forall x \in A$
  \end{nlist}

  Entonces, $\{f_k\} \to 0$ uniformemente en $A$.
\end{ejer}

  \begin{sol}
    Como $f_k(x) \to 0\ \ \forall x \in A$, entonces:  $$\forall \ x \in A,\ \forall \epsilon >0\ \exists k_x \in \mathbb{N}:\ k\geq k_x \implies |f_k(x)| < \frac{\epsilon}{2}$$
    Por otro lado, como $f_{k_x}$ es continua en $A$, en particular $f_{k_x}$ es continua en $x$. Por tanto, $\exists U_x$ entorno abierto de $x$ en $A$ tal que $$|f_{k_x}(y) - f_{k_x}(x)| < \frac{\epsilon}{2}\ \ \forall y \in U_x$$
    Observamos que $\forall x \in A, \ x \in U_x$. Por tanto $A \subseteq \bigcup_{x\in A} U_x$ $\implies \{U_x: x\in A\}$ es un recubrimiento por abiertos de $A$. Entonces, como $A$ es compacto, $\exists x_1,\dots,x_n \in A$ tales que $A \subseteq \bigcup_{i=1}^{n} U_{x_{i}}$. Sea ahora $k_0 = \text{máx}\{k_{x_1},\dots,k_{x_n}\}$, y es claro que $k \ge k_0 \implies k \ge k_{x_i}\ \forall i$.

    Entonces, dado $k \ge k_0$ se tiene que $|f_k(x_i)| < \epsilon/2 \ \ \forall i = 1,\dots,n$. También se verifica, puesto que $f_{k_{x_i}}$ es continua, que  $|f_{k_{x_i}} (y) - f_{k_{x_i}}(x_i)| < \epsilon/2$ \ \ $\forall y \in U_{x_i}, \ \forall i = 1,\dots,n$.

    Sea $y \in A \subseteq \bigcup_{i=1}^n U_{x_i} \implies \exists i \in \{1,\dots, n\}: y \in U_{x_i} \implies |f_{k_{x_i}}(y) - f_{k_{x_i}}(x_i)| < \epsilon/2$, y también $|f_{k_{x_i}}(x_i)| < \epsilon/2$. Sumando ambas expresiones, y utilizando la monotonía y la positividad de $\{f_k\}$, tenemos que: $$|f_k(y)| \leq |f_{k_{x_i}}(y)| \leq |f_{k_{x_i}} (x_i)| + |f_{k_{x_i}} (y) - f_{k_{x_i}}(x_i)| < \frac{2\epsilon}{2} = \epsilon$$

    En resumen, hemos probado que $\forall \epsilon > 0 \ \ \exists k_0 \in \N$ (depediente de $\epsilon$ y $x_1,\dots, x_n)$ tal que $k\geq k_0 \implies |f_k(y)| = f_k(y) < \epsilon \ \ \forall y \in A$.
  \end{sol}

\begin{ejer} Probar que en el espacio $\mathcal{C}(A,\mathbb{R}^M)$, con $A \subseteq \mathbb{R}^N$ compacto, cualquier bola cerrada y centrada en el origen es homeomorfa a una bola cerrada y centrada en un punto arbitrario.

\end{ejer}

\begin{sol}
    Sea $\epsilon > 0$, y $\tilde f \in \mathcal C (A, \mathbb{R}^M)$. Consideremos la aplicación $\varphi: \overline{B}_\infty(0,\epsilon) \to \ \overline{B}_\infty(\tilde f, \epsilon) $ dada por $\varphi(f) = f + \tilde f$.
    Por un lado, $\varphi$ está bien definida, pues: $$\|\tilde f - \varphi(f) \|_\infty= \| \tilde f - f - \tilde f \|_\infty = \|f\|_\infty \le \epsilon \Rightarrow \varphi(f) \in \overline{B}_\infty(\tilde f, \epsilon)$$
    Tenemos que $\varphi$ es continua, pues la preimagen de un entorno básico (bolas abiertas) es un entorno básico. Para verlo, en lugar de $\varphi$ vamos a tomar su extensión a todo el espacio (la llamaremos $\varphi'$), definiéndola de la misma forma ($f \mapsto f+\tilde f$). Entonces, se tiene que:
    \[
      \begin{array}{l}
	\varphi'^{-1}(B_\infty(f, \epsilon)) = \{ g\in \mathcal{C}(A,\R^M) : \varphi'(g) = g + 	\tilde f \in B(f, \epsilon)\} =\\
	= \{ g\in \mathcal{C}(A,\R^M) : \|f-\tilde f-g\|_\infty < \epsilon\} = B(f-\tilde f,\epsilon)
      \end{array}
    \]


    Además, la inversa de $\varphi$ existe: $\varphi^-1(g) = g - \tilde f\ \ \forall g \in \overline{B}_\infty(\tilde f, \epsilon)$. Es continua por el mismo motivo que $\varphi$.

    Por tanto, $\varphi$ es un homeomorfismo.
  \end{sol}


\begin{ejer}

  Sea $\{ f_n \}$ una sucesión de funciones reales uniformemente continuas en todo $\mathbb R$ que converge uniformemente a una función real $f$. ¿Puede concluirse que  la función $f$ es necesariamente uniformemente continua?
\end{ejer}

  \begin{sol}
    La respuesta es afirmativa. Veamos la prueba.

    Dado $\epsilon>0$, como $f_n \rightarrow f$ converge uniformemente, $\exists k>0$
    tal que $$n>k \Rightarrow |f_n(x)-f(x)| < \epsilon/3, \ \ \forall x \in A.$$
    Por otro lado, por ser $f_k$ uniformemente continua en $A$,
    $\exists \delta >0$ tal que $$\forall x,y \in A\ \textrm{con\ }|x-y| < \delta,\textrm{se\ tiene\ }|f_k(x)-f_k(y)| < \epsilon /3$$
    Juntando ambas informaciones: $$|f(x)-f(y)| \leq |f(x)-f_k(x)| + |f_k(x)-f_k(y)| + |f_k(y)-f(y)| < \epsilon$$
    Es decir, hemos probado que dado $\epsilon>0$, existe $\delta>0$ tal que $$\forall x,y \in A\ \textrm{con\ }|x-y|<\delta\ \textrm{se\ verifica\ }|f(x)-f(y)| < \epsilon$$
    Por tanto, $f$ es uniformemente continua.\qed
  \end{sol}

\begin{ejer}
  Estudiar la convergencia puntual y uniforme de la sucesión de funciones $f_n$ definidas en $[0,1]$ mediante $f_n(x) = x-x^n$ para todo $x\in [0,1]$.
\end{ejer}

 \begin{sol}
    Sabemos que para $0\le x<1$, $f_n(x)=x-x^n \to x$, y para $x=1$, tenemos que $f_n(x)=1-1^n = 0 \to 0$. Por tanto, el límite puntual es: $$f(x)= \left\{ \begin{array}{lcc} x & si & 0 \le x < 1 \\ \\ 0 & si & x=1  \end{array} \right.$$
    Como cada $f_n$ es continua y $f$ no es continua, no hay convergencia uniforme.
  \end{sol}

\begin{ejer}
  Estudiad la convergencia uniforme de la sucesión de funciones $f_n$ definidas en [$0,99999]$ mediante $f_n(x) = x^n$ para todo $x\in [0,99999]$.
\end{ejer}

  \begin{sol}
    En efecto, la sucesión de funciones converge uniformemente. En primer lugar, $\fn \xrightarrow {c.p} f=0$ por ser potencia de base menor que $1$. Además, por ser una función potencial, el valor máximo que toma es $0.99999^n$. Por tanto: $|x^n| \leq 0.99999^n \to 0$, luego $\fn$ converge uniformemente a $f=0$.
  \end{sol}

\begin{ejer}
  Estudiad la convergencia puntual y uniforme de la sucesión de funciones $f_n$ definidas en $[0,1]$ mediante $f_n(x) = (x-\frac{1}{n})^2$ para todo $x\in [0,1]$.
\end{ejer}

  \begin{sol}
    Sabemos que $\{\frac{1}{n}\} \to 0$, por lo que podemos afirmar que $\{f_n(x)\} \to x^2$ puntualmente en $[0,1]$. Veamos que también hay convergencia uniforme: $$|f_n (x) - x^2| = \left|-\frac{2x}{n} + \frac{1}{n^2} \right| \leq \frac{2}{n} + \frac{1}{n^2}\to 0, \ \forall x\in [0,1].$$
  \end{sol}

\begin{ejer}
  Estudiar el carácter de la siguientes series de funciones.

  \textbf{a)} $\ \displaystyle \sum_{n\geq1} \frac{sen^k(nx)}{n^2}, \quad k > 0$



  \textbf{b)} $\displaystyle \sum_{n\geq1} \left(\frac{x^n}{n!}\right)^2$



  \textbf{c)} $\displaystyle \sum_{n\geq1} \frac{1}{x^2+n^2}$



  \textbf{d)} $\displaystyle \sum_{k\geq1} \frac{x^k}{k^2}$


  \textbf{e)} $\displaystyle \sum_{k\geq1} k! x^k$

  \end{ejer}

\begin{sol}[a]
    Notemos lo siguiente: $\displaystyle |sen(nx)| \le 1 \implies \left|\frac{sen^k(nx)}{n^2}\right| \leq \frac{1}{n^2}$. Además, ya sabemos que la serie $\displaystyle \sum_{n \ge 1} \frac{1}{n^2}$ es convergente. Por tanto, aplicando el \textit{Criterio de Weierstrass}, tenemos que: $$\sum_{n\ge1} \frac{sen^k(nx)}{n^2}\ \text{converge uniformemente (y absolutamente).}$$
  \end{sol}

  \begin{sol}[b1] Podemos reescribir la serie tal que así: $\displaystyle \sum_{n\ge1} \frac{x^{2n}}{(n!)^2}$. Entonces, dado $M>0$, se tiene que, si $|x|\le M$:
    $$\begin{rcases}
      \frac{x^{2n}}{(n!)^2} \leq \frac{M^{2n}}{(n!)^2}\\
      \sum_{n\ge 1} \frac{M^{2n}}{(n!)^2} \ converge
    \end{rcases} \overset{\text{Criterio Weierstrass}}{\implies} \ \left(\frac{x^{n}}{n!}\right)^2 \ \text{es c.u en}\ [-M,M]$$

    Donde la convergencia de $\displaystyle \sum_{n\ge 1} \frac{M^{2n}}{(n!)^2}$ viene dada por el \textit{Criterio del cociente:} $$\lim_{n\to\infty}\ddfrac{\ddfrac{M^{2(n+1)}}{((n+1)!)^2}}{\frac{M^{2n}}{(n!)^2}} = \lim_{n\to\infty} \frac{M^2}{(n+1)^2} = 0 < 1.$$

    Como $M$ era una constante arbitraria, concluimos que la serie converge uniformemente en cualquier intervalo acotado de $\mathbb{R}$.
  \end{sol}

  \begin{sol}[b2] Podemos ver la serie como una serie de potencias $\displaystyle \sum_{k \ge 1} a_kx^k$, donde: $$a_k = \begin{cases} 0 & si \ k \ impar \\ \displaystyle \frac{1}{(n!)^2} & si \ k \ par \end{cases}$$

    Podemos aplicar el \textit{Criterio del cociente}, de forma muy similar al caso anterior, para ver que el radio de convergencia de la serie es $R = \infty$. Por tanto, $D(0,R) = \mathbb{R}$, y se tiene que $\forall M \in \mathbb{R}^+$ la serie converge uniformemente en $[-M,M]$.
  \end{sol}

   \begin{sol}[c]
    Nos basta la simple observación de que podemos acotar el término general de la serie (es siempre positivo) por una constante $M_n$, de tal suerte que $\sum_{n\ge1} M_n$ es convergente, y aplicar el \textit{Criterio de comparación}. Así: $$0 \le \frac{1}{x^2 + n^2} \le \frac{1}{n^2}\ \forall x \in \mathbb{R} \implies \sum_{n\ge 1} \frac{1}{x^2 + n^2} \ \text{converge uniformemente en } \mathbb{R}.$$

  \end{sol}

  \begin{sol}[d]
    Como es una serie de potencias, calculamos su radio de convergencia: $$R^{-1} = \lim_{k\to\infty} \frac{a_{k+1}}{a_k} = \lim_{k\to\infty} \ddfrac{\frac{1}{(k+1)^2}}{\frac{1}{k^2}} = \lim_{k\to\infty} \left(\frac{k}{k+1}\right)^2 = 1 \implies R = 1$$
    Por tanto, ya sabemos que la serie converge uniformemente cuando $|x| < 1$, y no converge cuando $|x| > 1$. Solo nos falta por estudiar el caso $|x|=1$: $$|x| = 1 \implies \left| \frac{x^k}{k^2} \right| = \frac{|x|^k}{k^2} = \frac{1}{k^2}$$

    Sabemos que $\displaystyle \sum_{k\ge1} \frac{1}{k^2}$ es convergente, por lo que, en virtud del \textit{Criterio de Weierstrass}, la serie $\displaystyle \sum_{k\ge1}\frac{x^k}{k^2}$ converge uniformemente cuando $|x| = 1$.
  \end{sol}

 \begin{sol}[e]
    Se trata de una serie de potencias, donde $a_k = k!$. Calculamos su radio de convergencia: $$R^{-1} = \lim_{k\to\infty} \frac{a_{k+1}}{a_k} = \lim_{k\to\infty} \frac{(k+1)!}{k!} = \lim_{k\to\infty} k + 1 = \infty \implies R=0$$

    Por tanto, la serie no converge si $|x| > R = 0$ (es decir, si $x\ne 0$). Si $|x| = 0$, tenemos que: $$\sum_{k\ge1} k! \cdot0^k = \sum_{k\ge1} 0 = 0 \ \text{(convergente)}$$
    En general, \textbf{una serie de potencias siempre es convergente en su centro}.
  \end{sol}


\begin{ejer}
  Probar que $\displaystyle \frac{1}{(1-x)^2} = \sum_{k=1}^\infty kx^{k-1}\ \ \forall x \in (-1,1)$
\end{ejer}

 \begin{sol}
    Para probarlo, se podría estudiar la convergencia de la serie de potencias, o también desarrollar el término de la izquierda como su suma de Taylor, y ver que coinciden. Sin embargo, procederemos de otro modo.

    En primer lugar, notemos que $\displaystyle kx^{k-1} = \frac{d}{dx}(x^k)$. Por tanto, estudiemos el carácter de la serie $\displaystyle \sum_{k\ge0} x^k$. Como es una serie de potencias, calculamos su radio de convergencia, y tenemos que $R = 1$, pues $a_k=1 \ \forall k \ge 0$.

    Por otro lado, consideramos la función $\displaystyle f(x) = \frac{1}{1-x}$. Sin mucho esfuerzo, podemos probar por inducción que $f^{k)}(0) = k! \ \ \forall k \ge 0$. Tenemos entonces que, tomando $a=0$ en el \textit{Teorema de Taylor} aplicado a $f(x)$: $$f(x) = \frac{1}{1-x} = \sum_{k=0}^\infty x^k \quad \forall x \in (-1,1),$$

    pues, en este caso, el resto de Taylor tiende a $0$ dentro del disco de convergencia. Sabemos también que la serie es derivable, y dentro del disco de convergencia, se da la siguiente igualdad, derivando en ambos miembros: $$\frac{1}{(1-x)^2} = \sum_{k=1}^\infty kx^{k-1}\quad \forall x \in (-1,1)$$
  \end{sol}

\begin{ejer}
  Encontrar un ejemplo de una sucesión de funciones $f_k: A \subseteq \mathbb{R} \to \mathbb{R}$ que cumpla:
  \begin{nlist}
  \item $\{f_k\} \to 0$ c.u.
  \item $\displaystyle \int_A f_k \not \to \int_A 0 = 0$
  \end{nlist}
\end{ejer}

\begin{sol}
    Sea $A = [0,+\infty)$, y tomo $f_k$ tales que $0 \le f_k(x) \le \frac{1}{k}$, y que además su integral se mantenga constante y distinta de 0. Un ejemplo de una tal función es:

    $$f_k(x) =
    \begin{cases}
      1/k & si \ \ 0 \le x \le k \\
      0 & si \ \ x \ge k
    \end{cases}$$

    Entonces, tenemos que $\displaystyle \int_0^\infty f_k(x)\ dx = \int_0^k \frac{1}{k}\ dx = 1 \to 1 \ne 0 $.
  \end{sol}

\newpage


% --------------------------------------------------------------------------------
% Integral asociada a una medida.
% --------------------------------------------------------------------------------

\section{Integral asociada a una medida}

\begin{ejer} Sean $B_1,B_2,\cdots,B_m \subseteq \Omega$ medibles y $\beta_1,\cdots,\beta_m\in[0,\infty)$. Entonces, la función $$t:= \sum_{k=1}^m \beta_k \upchi_{B_k}$$  es simple positiva.

  %%% FALTA DEMOSTRACIÓN ----------------------------------------------------------
\end{ejer}

% Ejercicios propuestos el 21-3. No tienen mucho que ver con la integral

\begin{ejer}
  Dado $p \in (1, +\infty)$ y sea $q = \frac{p}{p-1} \in (1, +\infty)$. Entonces $\frac{1}{p} + \frac{1}{q} = 1$.
\end{ejer}

\begin{ejer}
  Con $p, q$ definidos como en el ejercicio anterior:
  \begin{enumerate}
  \item $ \displaystyle ab \leq \frac{a^p}{p} + \frac{b^q}{q} \ \forall a, b \geq 0$ (Desigualdad de Young).
  \item Si $ \displaystyle ab = \frac{a^p}{p} + \frac{b^q}{q} \Leftrightarrow a^p = b^q$.
  \end{enumerate}
\end{ejer}

\begin{ejer}
  \begin{enumerate}
  \item $\mathcal L^{1} (\Omega)$ es un espacio vectorial.
  \item $\mathcal L^{\infty} (\Omega)$ es un espacio vectorial.
  \item $\mathcal L^{p} (\Omega)$ es un espacio vectorial.
  \end{enumerate}


\end{ejer}

\begin{sol}

    3.
    Dado $\alpha \in \mathbb K$, $f \in \mathcal L^p (\Omega)$. Entonces $\abs{\alpha f}^p = \abs{\alpha}^p \cdot \abs{f}^p$.
    Como $f, g \in \mathcal L^p(\Omega) \Rightarrow f + g \in \mathcal L^p(\Omega)$ y $ \displaystyle \left[ \int_{\Omega} |f+g|^{p} d \mu \right]^{\frac{1}{p}} \leq \left( \int_{\Omega} |f|^{p} d \mu \right)^{\frac{1}{p}} + \left( \int_{\Omega} |g|^{p} d \mu \right)^{\frac{1}{p}}$

    $$\int_{\Omega} \abs{f+g}^p d \mu = \int_{\Omega}\abs{f+g}^{p-1} \abs{f+g}d \mu \leq \int_{\Omega} \abs{f+g}^{p-1} \abs{f}d \mu + \int_{\Omega} \abs{f+g}^{p-1} \abs{g}d \mu$$

    Utilizando la desigualdad de Young:

    $$\leq \left[ \int_{\Omega} \left( |f+g|^{p-1} \right)^q d \mu \right]^{\frac{1}{q}} \left[ \int_{\Omega} |f|^{p} d \mu \right]^{\frac{1}{p}} + \left[ \int_{\Omega} \left( |f+g|^{p-1} \right)^q d \mu \right]^{\frac{1}{q}} \left[ \int_{\Omega} |g|^{p} d \mu \right]^{\frac{1}{p}}$$

    $$= \left[ \int_{\Omega} |f+g|^{p} d \mu \right]^{\frac{1}{q}} \left[ \int_{\Omega} |f|^{p} d \mu \right]^{\frac{1}{p}} + \left[ \int_{\Omega} |f+g|^{p} d \mu \right]^{\frac{1}{q}} \left[ \int_{\Omega} |g|^{p} d \mu \right]^{\frac{1}{p}}$$

    $$= \left[ \int_{\Omega} |f+g|^{p} d \mu \right]^{\frac{1}{q}} \left[ \left( \int_{\Omega} |f|^{p} d \mu \right)^{\frac{1}{p}} + \left( \int_{\Omega} |g|^{p} d \mu \right)^{\frac{1}{p}} \right]$$

    $$= \left[ \int_{\Omega} \left[ |f|+|g| \right]^{p} d \mu \right]^{\frac{1}{q}} \left[ \left( \int_{\Omega} |f|^{p} d \mu \right)^{\frac{1}{p}} + \left( \int_{\Omega} |g|^{p} d \mu \right)^{\frac{1}{p}} \right]$$

    $$ \leq 2^{p-1} \int_{\Omega} \left( |f|^p + |g|^p) d \mu \right)^{\frac{1}{q}} < \infty$$

  \end{sol}


\begin{ejer}
  Dada $g : \Omega \rightarrow \mathbb R$ medible positiva. Entonces:

  $$\int_{\Omega} g d \mu = 0 \Leftrightarrow g = 0 \text{ a. e. } x \in \Omega$$
\end{ejer}

\begin{ejer}
  Dado $\Omega \subset \mathbb R^N \text{ compacto, } g: \Omega \rightarrow \mathbb R \text{ cont. } \Rightarrow$ g es integrable. Si además $\int_{\mathbb R} |g| d \mu = 0 \Rightarrow g(\omega) = 0 \ \forall \omega \in \Omega$.
\end{ejer}

\begin{ejer}
  Dados $\Omega \supset E_{1,k} \supset E_{2,k} \supset \hdots \supset E_{n,k} \supset
  E_{n+1,k} \supset \hdots$ entonces si $\mu(\Omega) < \infty \Rightarrow
  \lim_{n\to\infty} \mu(E_{n,k}) = \mu(\bigcap_{n \in \mathbb N}
  E_{n,k})$.
\end{ejer}

\begin{ejer}
  Definimos un espacio métrico con $\Omega = \mathbb R$ y $\mu =$ la medida de Lebesgue en $\mathbb R$
  (sabiendo que $\mu(\mathbb R) = \infty$).

  Si definimos la función $f_n(\omega) = \chi_{[n,n+1]}(\omega) \rightarrow 0 \ \
  \forall \omega \in \R$, probar que ${f_n}$ no converge uniformemente a 0 en un
  conjunto $F \subseteq \R$ medible tal que $\forall \varepsilon > 0 \ \ \mu(\R
  \setminus F) < \varepsilon < \infty$.

  \textit{Pista: Utilizar que $\mu(\R \setminus F) < \infty \Rightarrow \mu(F) =
    \infty$ (es decir, es posible tomar puntos tan separados como se quieran)}
  % Hacer el dibujo que tengo (jmml) en un papel

  \pgfdeclarelayer{bg}
  \pgfdeclarelayer{fg}
  \pgfsetlayers{bg,main,fg}

  \sffamily
    \begin{tikzpicture}[scale=1.4]
    \draw[help lines, color=gray!30, dashed] (-0.9,-0.9) grid (8.9,2.9);
    \begin{pgfonlayer}{fg}
    \draw[->,ultra thick] (-1,0)--(9,0) node[right]{$$};
    \draw[->,ultra thick] (0,-1)--(0,3) node[above]{$$};
    \end{pgfonlayer}{fg}
    \foreach \x/\xtext in {1/1, 2/2, 3/3, 4/ \omega, 5/n, 6/n+1, 7/m, 8/m+1}
    \draw[shift={(\x,0)}] (0pt,2pt) -- (0pt,-2pt) node[below] {$\xtext$};
    \draw[shift={(0,0)}] (2pt,0pt) -- (-2pt,0pt) node[below left] {$0$};
    \foreach \y/\ytext in {1/1, 2/2}
    \draw[shift={(0,\y)}] (2pt,0pt) -- (-2pt,0pt) node[left] {$\ytext$};
    \coordinate (A) at (1,1);
    \coordinate (B) at (2,1);
    \draw[700] (A) -- node [above] {$f_1$} (B) ;
    \draw[700, dashed, thick] (1,0) -- (A);
    \draw[700, dashed, thick] (2,0) -- (B);
    \fill [300] (1,0) -- (A) -- (B) -- (2,0);
    \coordinate (N) at (5,1);
    \coordinate (N+1) at (6,1);
    \draw[700, thick] (N) -- node [above] {$f_n$} (N+1);
    \begin{pgfonlayer}{fg}
    \draw[700, dashed, thick] (N) -- (5,0);
    \draw[700, dashed, thick] (N+1) -- (6,0);
    \end{pgfonlayer}{fg}
    \fill [300] (N) -- (5,0) -- (6,0) -- (N+1);
    \coordinate (M) at (7,1);
    \coordinate (M+1) at (8,1);
    \draw[700] (M) -- node [above] {$f_m$} (M+1);
    \draw[700, dashed, thick] (M) -- (7,0);
    \draw[700, dashed, thick] (M+1) -- (8,0);
    \fill [300] (M) -- (7,0) -- (8,0) -- (M+1);
  \end{tikzpicture}
    \captionof{figure}{Representación gráfica de la función $f_n(\omega)$}


\end{ejer}

\begin{ejer}
  (Continuidad absoluta de la integral). Dado $(\Omega, \mathcal A, \mu)$ un espacio de medida y $f \in \mathcal
  L^1(\Omega)$ con $f \in \mathcal L^1(\Omega)$. Demostrar que $\forall \varepsilon
  > 0 \exists \delta > 0$ tal que si $E \in \mathcal A$ y $\mu(E) < \delta$
  entonces $\int_E |f|d\mu < \varepsilon$
\end{ejer}

  \begin{sol}
    Veamos una primera demostración.

    Sea $\varepsilon$ un número positivo cualquiera. Como $|f|$ es integrable,
   $ \int_{\Omega} |f| d\mu = \text{ sup } \{ \int_{\Omega}sd\mu : \text{s
     simple positiva y } S \leq |f|$\}. Entonces $\exists s : \Omega \rightarrow
   [\Omega, \infty)$ simple tal que $$0 \leq \int_{\Omega}(|f| - s)d\mu <
   \varepsilon$$

   Así, tenemos que $\forall E \in \mathcal A$

   $$\int_E |f| d \mu = \int_E (|f| - s)d\mu + \int_E s d\mu \leq \int_{\Omega}
   (|f| -s)d\mu + \int_E s d \mu < \varepsilon + \int_E s d \mu$$

   Si elijo $\displaystyle \delta = \frac{\varepsilon}{1 + \sum_{i=1}^n |\alpha_i|}$, como $|f| =
   s$ es simple y $\mu(E) < \delta$ entonces $$\int_E sd\mu
    = \sum_{i=1}^n \alpha_i \mu (A_i \cap E) \leq \left[ \sum_{i=1}^n |\alpha_i|
    \right] \mu (E) \leq \frac{\sum_{i=1}^n |\alpha_i|}{1 + \sum_{i=1}^n
      |\alpha_i|} \varepsilon < \varepsilon $$

    Por tanto, $\mu(E) < \delta$ y $E \in \mathcal A \Rightarrow \int_E |f|d\mu
    < \varepsilon + \int_e s d \mu < \varepsilon + \varepsilon = 2\varepsilon$

    \begin{nota}
      Si desde un principio tomamos $\frac{\varepsilon}{2}$ en lugar de
    simplemente $\varepsilon$ nos quedará $\varepsilon$ al final y no $2\varepsilon$.
    \end{nota}

  \end{sol}

\begin{ejer}
  Dada una función $f: k \rightarrow \R$ continua y $K \subset \R^N$ un
  compacto, entonces $f \in \mathcal L^1(K)$.
\end{ejer}

  \begin{sol}
    Para obtener la solución vamos a usar que $f \in L^1(K) \Leftrightarrow |f|
    \in \mathcal L^1(K)$.

    $f$ es medible.

    Como $f$ es continua, $f^{-1}((-\infty, \gamma)) = \{ x \in K : f(x) <
    \gamma\}$ abierto en $\R^N \forall \gamma \in \R \Rightarrow
    f^{-1}((-\infty, \gamma)) \in \mathcal B \subset$ medibles de Lebesgue en
    $\R^N$.

    Como $f$ es continua, $|f|$ también lo es, con lo que $|f|$ es medible
    positiva.

    Dado $K$ un compacto y $|f|$ una función continua, por el Teorema de
    Weierstrass $\exists M > 0 : |f(x)| \leq M \forall x \in K$.

    $|f| \leq M = M \chi_k$ luego $$\int_K Md\mu = M\mu(K) \leq M \mu (B) <
    \infty$$ $$\int_K |f|d\mu \leq \int_K Md\mu \leq M\mu(B) < \infty \Rightarrow
    |f| \in \mathcal L^1(K).$$

  \end{sol}

\begin{ejer}
  Dada una función $g : \Omega \rightarrow \R$ medible, $\Omega \in \R^N$
  medible, con $\mu(\Omega) < \infty$. Entonces, $ g \in L^1(\Omega)$. Prueba
  además que $\exists M, m \in \R : m \leq g(x) \leq M \forall x \in \Omega$.
\end{ejer}

\begin{ejer}
  Si $\{f_n\} \subset \mathcal C(k, \R), k \in \R^N$ compacto y $\{f_n(x)\}
  \rightarrow f(x) \forall x \in K$, prueba que $\{f_n\} \rightarrow f$ c.u. en
  $K \Leftrightarrow \{f_n : n \in \N\}$ es equiacotada y equicontinua.
\end{ejer}

\begin{ejer}[Aplicación Th. Fubini]
  Sean $\varphi, \psi : [a, b] \rightarrow \R$ continua, tal que $\varphi(x)
  \leq \psi(x), x \in [a, b]$. Definamos el conjunto $A = \{ (x, y) \in \R^2 : a
  \leq x \leq b, \varphi(x) \leq y \leq \psi(y) \}$. Definimos $f : A
  \rightarrow \R$ integrable. Probar que
  $$ \int_A f(x, y) \ dxdy = \int_a^b \left( \int_{\varphi(x)}^{\psi(x)} f(x,y)
    \ dy \right) \ dx$$
\end{ejer}

\begin{sol}
%  $$\int_A f \ dxdy = \int_{\R^2} f(x, y) \rchi_A(x,y) \ dxdy$$
\end{sol}

\begin{ejer}
  Calcula la integral $\displaystyle \int_A sen^2x \ sen^2y \ dxdy$ en el conjunto
  $A = [0, \pi] \times [0, \pi]$.
\end{ejer}

\begin{sol}
  \begin{align*}
    \int_A sen^2 \ x sen^2 \ y \ dxdy = \int_{0}^{\pi}\left(\int_0^{\pi} sen^2 \
    x \ sen^2 \ y \ dy \right) dx
    \end{align*}
\end{sol}

\begin{nota}
  Si $A = [a, b] \times [c, d]$, entonces $$ \int_A f \ dxdy = \int_a^b \left(
    \int_c^d f \ dy \right) dx$$
\end{nota}

\begin{ejer}
  Sean $\phi, \psi : [c, d] \rightarrow \R$ continuas tales que $\phi(y) \leq
  \psi(y) \forall y \in [c, d]$. Dado el conjunto $A = \{ (x,y) \in \R^2, \ \ c
  \leq y \leq d, \ \ \phi(y) \leq \psi(y) \}$. Sabiendo que $f : A \rightarrow
  \R$ es integrable, demuestra que su integral es:

   \begin{align*}
    \int_A = f \ dxdy = \int_c^d \left( \int_{\phi(y)}^{\psi(y)} f(x,y) \ dx
    \right) dy
   \end{align*}

   Puedes probar a desmotrarlo con el Teorema de Fubini general.
 \end{ejer}

\begin{ejer}
    $\int_A x \ dxdy$, $A = \{ (x,y) \in \R^2 : x^2 + y^2 \leq 2 \} = f^{-1}((-\infty, 0])) \ \ \ f(x,y) = x^2+y^2-2x$ es continua y medible.
\end{ejer}

\begin{sol}
    Primero intentamos dibujar el conjunto A. Podemos imaginarnos también el conjunto A en coordenadas polares. Así, $x = \rho \ cos \theta$ y $y = \rho \ sen \theta $ con $\rho \in [0, +\infty)$ y $\theta \in (-\pi, \pi)$. Por tanto, el conjunto $A' = \{ (\rho, \theta) \in [0, +\infty) \times (-\pi, \pi) : \rho \leq 2 \rho / cos \theta \}$.

    Así, \begin{align*}
        \displaystyle \int_A x \ d(x,y) = \int_A x \ dxdy = \int_{A'} \rho \ \cos \theta \ \rho d\rho d\theta= \int_{-\pi}^{\pi} \left[ \int_0^{2cos \theta}  \rho^2 \ cos \theta \ d\rho\right]d\theta
    \end{align*}

    Ahora, por el Teorema de Fubini:
    \begin{align*}
    \int_0^{2cos\theta} \rho^2 cos \theta \ d\rho = \left[ \frac{\rho^3cos\theta}{3} \right]^{\rho = 2cos \theta} = \frac{8cos^4 \theta}{3}
    \end{align*}
    \begin{align*}
        \label{}
        \int cos^4 \theta \ d\theta &= \int cos^2 \theta cos^2 \theta \ d\theta = \int \frac{1 + cos(2\theta)}{2} \frac{1 + cos (2 \theta)}{2} / d \theta \\
                                    &= \frac{1}{4} \int [1 + 2cos(2\theta) + cos^2(2 \theta)] \ d\theta = \hdots + \frac{1}{4} \int cos^2(2\theta) \ d\theta
    \end{align*}
    % FIXME: Miguel va a acabar este ejercicio.
\end{sol}

\begin{ejer}
    Calcula el volumen de $A = \{ (x,y,z) \in \R^3 : 1 \leq x^2 + y^2 \leq 2, 2(x^2+y^2) \leq 1, z \geq 0 \}$.
\end{ejer}

\begin{sol}
    Decimos entonces que \begin{align*}
        \label{}
        Vol A = \int_A 1 \ dxdydz = \int_{\R^3} \Xi_A (x,y,z) \ dxdydz = \text{medida}(A)
    \end{align*}
    Vamos a utilizar coordenadas cilíndricas:
    $$\begin{cases}
        x = \rho \ cos \theta \\
        y = \rho \ sen \theta \\
        z = z
    \end{cases}$$ teniendo en cuenta que  $x^2 + y^2 = \rho^2$.

    Definimos el conjunto $A' = \{(\rho, \theta, z) : 1 \leq \rho^2 \leq 2, z\rho^2 \leq 1, z \geq 0 \} = \{ (\rho, \theta, z) \in [0, +\infty) \times (-\pi, \pi) \times \R : 1 \leq \rho \leq \sqrt{2}, 0 \leq z \leq \frac{1}{\rho^2} \}$. Intentamos dibujar el conjunto:
    % TODO: ¿Hacer el dibujo?

    Ahora vamos a calcular la integral del conjunto $A'$.

    \begin{align*}
        \label{}
        \int_A 1 \ dxdydz &\underset{\text{cambiamos a cilíndricas}}{=} \int_{A'} 1 \ \rho d\rho d\theta dz \underset{Fubini/Tonelli}{=} = \int_{-\pi}^{\pi}\left( \int 1 \ d\rho dz \right) \ d\rho \\
                          &= \int_{-\pi}^{\pi} \int_1^{\sqrt{2}} \left( \int_0^{\frac{1}{\rho^2}} 1 \ dz \right) \ d\rho \ d\theta = \int_{-\pi}^{\pi} \int_1^{\sqrt{2}} \left( \frac{1}{\rho} d \ \rho \right) \ d\theta \\
                          &= \int_1^{\sqrt{2}} \int_{-\pi}^{\pi} \frac{1}{\rho} \ d \theta d \rho = 2\pi \int_1^{\sqrt{2}} \frac{1}{\rho} d\rho \\
                          &= 2\pi [ln \sqrt{2} - ln 1]
    \end{align*}

\end{sol}

    \begin{ejer}[Fórmula de Liouville]
        Calcula la siguiente integral: $$\int_0^{+\infty} e^{-x^2} \ dx$$
    \end{ejer}

    \begin{ejer}
        Calcula la siguiente integral: $$\int_0^{\infty} \frac{sen \ x}{x} \ dx$$
    \end{ejer}

    \begin{sol}
        Dado un $R > 0$, definimos la función $F(x,y) = e^{-xy} \ sen(x)$ tal que $F : [0, R] \times [0, \infty) \rightarrow \mathbb R$. Nótese que es una función de dos variables.

        \begin{align*}
            \label{}
            \int e^{-xy} \ sen x \ dx &\left( \begin{cases}
                h = sen \ x \\
                dv = e^{-xy} \ dx \\
                v = \frac{e^{-xy}}{-y}
    \end{cases} \right) = - \frac{e^{-xy} \ sen x}{y} + \frac{1}{y} \int e^{-xy} \ cos x \ dx \\
                                      &= - \frac{e^{xy} \ sen x}{y} + \frac{1}{y} \left( - \frac{e^{xy} \ cos x}{y} - \int \frac{e^{-xy}}{y}(sen x) \ dx \right) \\
                                      &= - \frac{e^{-xy} \ sen x}{y} - \frac{e^{-xy} \ cos x}{y^2} - \frac{1}{y^2} \int e^{-xy} \ sen x \ dx
        \end{align*}
        \begin{align*}
            \label{}
            \int e^{-xy} \ sen x \ dx = -e^{-xy} \left[ \frac{sen x}{y} + \frac{cos x}{y^2} \right] \cdot \frac{y^2}{1+y^2} = -e^{-xy} \frac{y \ sen x + cos x}{1 + y^2}
        \end{align*}
        \begin{align*}
            \label{}
            \int_0^{R} e^{-xy} \ sen x \ dx = -e^{Ry} \frac{y \ sen R + cosR}{1+y^2} + \frac{1}{1 + y^2} = \frac{1 - e^{Ry} [y \ senR + cosR]}{1 + y^2}
        \end{align*}
        % FIXME: Por Fubini se puede hacer en ambos sentidos.
                \begin{align*}
            \label{}
            \int_{[0, R] \times [0, \infty)} F(x,y) \ dxdy &= \int_{0}^{+\infty} \left( \int_0^{R} e^{-xy} \ senx \ dx \right) dy \\
                                                           &= \int_0^{+\infty} \frac{1}{1+y^2} \left[ 1 - e^{-Ry} (y \ sen R + cos R) \right] dy
        \end{align*}

    Para simplificar la notación a continuación, llamamos $$ g(y, R) =  \frac{1}{1+y^2} \left[ 1 - e^{-Ry} (y \ sen R + cos R) \right]$$

        Para acabar nos queda calcular el valor del límite:
        \begin{align*}
            \label{}
            \lim_{R \to \infty} \int_0^{\infty} g(y, R) \ dy = \int_0^{\infty} \lim_{R \to \infty} g(y,R) \ dy = \int_{0}^{\infty} \frac{1}{1+y^2} \ dy = \frac{\pi}{2}
        \end{align*}

        \begin{align*}
            \label{}
            \lim_{n \to \infty} \int_0^{\infty} g(y, R_n) \ dy &\underset{th. \ conv. \ dominada}{=} \int_0^{\infty} \lim_{n \to \infty} g(y, R_n) = \int_0^{+\infty} \frac{1}{1 + y^2} \ dy \\
                                                               &= \frac{\pi}{2}
        \end{align*}
            \end{sol}

            \begin{ejer}[Principio de Cavalieri]
                Sea $E \subset \R^2$ un conjunto medible. Dado el subconjunto $$\left\{ x \in \R : \emptyset \neq E(x) = \left\{ (y, z) \in \R^2 : (x, y, z) \in E \right\} \right\} = [a, b]$$ su medida $m_3(E) = \int_a^b m_2(E(x)) \ dx $.
            \end{ejer}

            \begin{sol}
                Por ejemplo, para el conjunto  $E = [a, b] \times B_{\R^2} (0, r)$ tenemos que \begin{align*}
                    \label{}
                    \forall x \in [a, b] \ \ E(x) = \left\{ (y, z) \in \R^2 : (x, y, z) \in E \right\} = B_{\R^2}(0, r) \\
                    m_3(E) = \int_a^b m_2 (B_{\R^2}(0, r)) \ dx = m_2(B_{\R^2}(0, r)) \cdot (b - a) = \pi \cdot r^2 \cdot (b -a)
                \end{align*}
                Probemos ahora la proposición.
                \begin{align*}
                    \label{}
                    m_3(E) = \int_{\R^3} \rchi_E (x, y, z) \ dxdydz = \int_E 1 \ dxdydz &= \int_a^b \left( \int_{E(x)} \ dydz \right) \ dx \\
                            &= \int_a^b m_2(E(x)) \ dx
                \end{align*}
            \end{sol}

            \begin{ejer}
                $\int (x^2 + y^2) \ dxdxy$, $\overline{B}_{\R^3} (1, 0, 1)$. $f(x, y) := x^2+y^2$ es ''Radial'' ya que su valor sólo depende de $r = \sqrt{x^2+y^2}$.
            \end{ejer}

            \begin{sol}
                \begin{align*}
                    \label{}
                    \int (x^2 + y^2) \ dxdxy = \int_0^1 \left(  \int_{\pi}^{\pi} r^2 \cdot r \ d\theta \right) \ dr &= \int_0^1 r^3 \cdot 2\pi \ dr \\
                            &= 2\pi \frac{r^4}{4} \bigg\rbrack_{r=0}^{r=1} = \frac{\pi}{2}
                \end{align*}

                Para la radial hacemos un cambio a coordenadas polares: $$ \begin{rcases}
                    x = r \ cos \theta \\
                    y = r \ sen \theta
                \end{rcases}$$

                Describamos ahora el conjunto $\overline{B}(1, 0, 1)$ \begin{align*}
                    \label{}
                    \left\{ (x, y) \in \R^2 : (x-1) + y^2 \leq 1 \right\} &= \left\{ (r, \theta) \in [0, \infty) \times [-\pi, \pi] : (r \ cos \theta - 1)^2 + (r \ sen \theta)^2 \leq 1 \right\} \\
                        A &= \left\{ (r, \theta) \in [0, \infty) \times [-\pi, \pi] : r^2-2r \ cos \theta \leq 0 \right\}
                \end{align*}

                Si tomamos $$ \begin{rcases}
                    x = 1 + r \ cos \theta \\
                    y = 0 + r \ sen \theta
                \end{rcases}$$
                tendremos al final un rectángulo, por lo que calcular el área es muy sencillo con Fubini.
                \begin{align*}
                    \label{}
                    (x, y) &= (1, 0) + (r cos \theta, r \ sen \theta) \\
                    \overline{B}((1, 0), 1) &= (1, 0) + \overline{B} ((0, 0), 1) \rightarrow B = \left\{ (r, \theta) : 0 \leq r \leq 1; -\pi < \theta \leq \pi \right\} = [0, 1] \times (-\pi, \pi] \\
                    \int_{\overline{B}((1, 0), 1)}(x^2 + y^2) \ dxdy &= \int_B \left( (1 + rcos^2 \ \theta)^2 + r^2 \ sen^2 \ \theta \right) r \ drd\theta \\
                        &= \int_0^1 \int_{-\pi}^{\pi} (r^3 + 2r^2 \ cos \theta + r) \ d\theta dr
                \end{align*}
            \end{sol}

            \begin{ejer}
                Calcula $\int_A (x^2 + y^2) \ dxdy $ con
                \begin{align*}
                    A &= \left\{ (x,y) \in \R^2 : x^2 + y^2 \leq 2y, x^2 + y^2 \leq 1, x > 0 \right\}
                \end{align*}
            \end{ejer}

            \begin{sol}
                Vemos que $A = B_{\R^2} (0,1),1) \cup B_{\R^2} ((0,0),1) \cup \lbrack\text{Primer y cuarto cuadrante}\rbrack$.

                Hacemos el cambio de coordenadas: $$ \begin{rcases}
                    x = r \ cos \ \theta \\
                    y = r \ sin \ \theta
                \end{rcases}$$

                Llamamos $B$ al conjunto anterior con las nuevas coordenadas:
                \begin{align*}
                    \label{}
                    B = \left\{ (r, \theta) \in (0,1) \times (0, \frac{\pi}{2}) : r \leq 2 \ sen \theta \right\}
                \end{align*}
                \begin{align*}
                    \label{}
                    \int_A (x^2 + y^2) \ dxdy &= \int_B r^3 \ drd\theta = \int_0^1 \left( \int_{arcsen(\frac{r}{2})}^{\frac{\pi}{2}} r^3 \ d\theta \right) \ dr \\
                    \text{alternativamente,} \\
                    &= \int_{\frac{\pi}{6}}^{\frac{\pi}{2}} \left( \int_0^1 r^3 \ dr \right) \ d\theta + \int_0^{\frac{\pi}{6}} \left( \int_0^{2sen \ \theta} r^3 \ dr \right) \ d\theta
                \end{align*}


                {\sffamily \textit{De forma cartesiana:}}

                Calculamos la intersección de los conjuntos: \begin{align*}
                    \label{}
                    \begin{rcases}
                        x^2 + y^2 = 1 \\
                        x^2 + (y-1)^2 = 1
                    \end{rcases} \Rightarrow \begin{rcases}
                        x^2 = 1 - y^2 \\
                        x^2 = 1 - (y-1)^2
                    \end{rcases} &\Rightarrow y^2 = (y - 1)^2 = y^2 - 2y + 1 \\
                    1 = 2y &\Rightarrow y = \frac{1}{2} \\
                    x^2 = 1 - \frac{1}{4} = \frac{3}{4} &\Rightarrow x = \pm \frac{\sqrt{3}}{2}
                \end{align*}
                La integral es entonces \begin{align*}
                    \label{}
                    \int_A (x^2 + y^2) \ dxdy &= \int_0^{\frac{\sqrt{3}}{2}} \left( \int_{1 - \sqrt{1-x^2}}^{\sqrt{1-x^2}} (x^2 + y^2) \ dx \right) \ dy \\
                                              &= \int_{0}^{\frac{\sqrt{3}}{2}} \bigg\lbrack x^2y + \frac{y^3}{3} \bigg\rbrack_{y=1 - \sqrt{1-x^2}}^{y=\sqrt{1-x^2}} \ dx = \hdots
                \end{align*}
            \end{sol}
